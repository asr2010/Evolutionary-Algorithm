{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Load and preprocess the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = tf.keras.utils.to_categorical(y_train), tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "validation_split = 0.1\n",
    "split_index = int(len(x_train) * validation_split)\n",
    "x_val, y_val = x_train[:split_index], y_train[:split_index]\n",
    "x_train, y_train = x_train[split_index:], y_train[split_index:]\n",
    "\n",
    "sample_size = 5000  # Adjust this value as needed\n",
    "sample_indices = np.random.choice(np.arange(x_train.shape[0]), sample_size, replace=False)\n",
    "\n",
    "x_train_small = x_train[sample_indices]\n",
    "y_train_small = y_train[sample_indices]\n",
    "\n",
    "# Define the fitness function\n",
    "def fitness_function(num_filters1, num_filters2, dense_units, learning_rate):\n",
    "    num_filters1 = max(1, round(num_filters1))\n",
    "    num_filters2 = max(1, round(num_filters2))\n",
    "    dense_units = max(1, round(dense_units))\n",
    "    print(f\"num_filters1: {num_filters1}, num_filters2: {num_filters2}\")\n",
    "    model = Sequential([\n",
    "        Conv2D(num_filters1, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(num_filters1, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(num_filters2, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(num_filters2, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(dense_units, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(x_train_small, y_train_small, epochs=10, batch_size=256,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=0)\n",
    "\n",
    "    return history.history['val_loss'][-1]\n",
    "\n",
    "# Define the ACO class\n",
    "class ACO:\n",
    "    def __init__(self, fitness_function, colony_size, n_iterations, num_params, lower_bounds, upper_bounds, alpha, beta, rho, q, seed=None, num_discrete_values=10, randomness_factor=0.1):\n",
    "        self.fitness_function = fitness_function\n",
    "        self.colony_size = colony_size\n",
    "        self.n_iterations = n_iterations\n",
    "        self.num_params = num_params\n",
    "        self.lower_bounds = lower_bounds\n",
    "        self.upper_bounds = upper_bounds\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.rho = rho\n",
    "        self.q = q\n",
    "        self.seed = seed\n",
    "        self.num_discrete_values = num_discrete_values\n",
    "        self.randomness_factor = randomness_factor\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # Create the discretized search space for each parameter\n",
    "        self.discrete_values = [np.linspace(lower_bounds[i], upper_bounds[i], num=self.num_discrete_values) for i in range(self.num_params)]\n",
    "\n",
    "        # Initialize the pheromone matrix\n",
    "        self.pheromone_matrix = np.ones((self.num_params, self.num_discrete_values))\n",
    "\n",
    "    def run(self):\n",
    "        best_solution = None\n",
    "        best_fitness = float('inf')\n",
    "\n",
    "        for iteration in range(self.n_iterations):\n",
    "            solutions = []\n",
    "            fitnesses = []\n",
    "            discrete_solution_indices_list = []\n",
    "\n",
    "            for ant_index in range(self.colony_size):\n",
    "                solution = []\n",
    "                discrete_solution_indices = []\n",
    "\n",
    "                for i in range(self.num_params):\n",
    "                    probabilities = self.pheromone_matrix[i] ** self.alpha * (1 / self.discrete_values[i]) ** self.beta\n",
    "                    probabilities /= np.sum(probabilities)\n",
    "                    \n",
    "                    # Add randomness\n",
    "                    if random.random() < self.randomness_factor:\n",
    "                        discrete_index = random.randint(0, self.num_discrete_values - 1)\n",
    "                    else:\n",
    "                        discrete_index = np.random.choice(np.arange(self.num_discrete_values), p=probabilities)\n",
    "\n",
    "                    solution.append(self.discrete_values[i][discrete_index])\n",
    "                    discrete_solution_indices.append(discrete_index)\n",
    "\n",
    "                # Print progress before evaluating the fitness\n",
    "                print(f'Iteration {iteration + 1}, Ant {ant_index + 1}: Evaluating...')\n",
    "                fitness = self.fitness_function(*solution)\n",
    "\n",
    "                solutions.append(solution)\n",
    "                fitnesses.append(fitness)\n",
    "                discrete_solution_indices_list.append(discrete_solution_indices)\n",
    "\n",
    "                if fitness < best_fitness:\n",
    "                    best_fitness = fitness\n",
    "                    best_solution = solution\n",
    "\n",
    "                # Print progress of each ant\n",
    "                print(f'Iteration {iteration + 1}, Ant {ant_index + 1}: Current solution: {solution}, Current validation loss: {fitness}')\n",
    "\n",
    "            # Update pheromone levels after all ants have completed their search in the current iteration\n",
    "            for ant_index in range(self.colony_size):\n",
    "                fitness = fitnesses[ant_index]\n",
    "                discrete_solution_indices = discrete_solution_indices_list[ant_index]\n",
    "                for i in range(self.num_params):\n",
    "                    self.pheromone_matrix[i] *= (1 - self.rho)\n",
    "                    self.pheromone_matrix[i, discrete_solution_indices[i]] += self.q / fitness\n",
    "\n",
    "            print(f'Iteration {iteration + 1}: Best solution: {best_solution}, Best validation loss: {best_fitness}')\n",
    "\n",
    "        return best_solution, best_fitness\n",
    "\n",
    "\n",
    "\n",
    "# Set the ACO hyperparameters and bounds for the CNN hyperparameters\n",
    "colony_size = 20\n",
    "n_iterations = 20\n",
    "num_params = 4\n",
    "lower_bounds = [16, 16, 256, 0.0001]\n",
    "upper_bounds = [128, 128, 1024, 0.01]\n",
    "alpha = 1.5\n",
    "beta = 4\n",
    "rho = 0.8\n",
    "q = 0.3\n",
    "randomness_factor = 0.5\n",
    "\n",
    "# Create and run the ACO optimizer\n",
    "print(\"Starting the ACO optimizer...\")\n",
    "aco = ACO(fitness_function, colony_size, n_iterations, num_params, lower_bounds, upper_bounds, alpha, beta, rho, q, seed=42,randomness_factor=randomness_factor)\n",
    "best_hyperparameters, best_val_loss = aco.run()\n",
    "\n",
    "best_num_filters1, best_num_filters2, best_dense_units, best_learning_rate = best_hyperparameters\n",
    "best_num_filters1, best_num_filters2, best_dense_units = int(best_num_filters1), int(best_num_filters2), int(best_dense_units)\n",
    "\n",
    "print(f\"Best hyperparameters found by ACO: num_filters1={best_num_filters1}, \"\n",
    "      f\"num_filters2={best_num_filters2}, dense_units={best_dense_units}, \"\n",
    "      f\"learning_rate={best_learning_rate}\")\n",
    "\n",
    "# Train the model with the best hyperparameters found by ACO\n",
    "print(\"Training the model with the best hyperparameters...\")\n",
    "\n",
    "# Train the model with the best hyperparameters found by ACO\n",
    "best_model = Sequential([\n",
    "    Conv2D(best_num_filters1, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(best_num_filters1, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(best_num_filters2, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(best_num_filters2, (3, 3), activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(best_dense_units, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "best_model.compile(optimizer=Adam(learning_rate=best_learning_rate),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "start_time = time.time()\n",
    "history = best_model.fit(x_train, y_train, epochs=50, batch_size=64,\n",
    "                         validation_data=(x_val, y_val),\n",
    "                         callbacks=[early_stopping],\n",
    "                         verbose=1)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(f'Total training time: {training_time:.2f} seconds')\n",
    "\n",
    "# Evaluate the best model on the test dataset\n",
    "print(\"Evaluating the model on the test dataset...\")\n",
    "test_loss, test_acc = best_model.evaluate(x_test, y_test, verbose=0)\n",
    "y_pred = best_model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_classes, y_pred_classes))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_classes, y_pred_classes))\n",
    "\n",
    "# Calculate ROC-AUC for multi-class classification\n",
    "roc_auc = roc_auc_score(y_test, y_pred, multi_class='ovr')\n",
    "print(f'ROC-AUC Score: {roc_auc}')\n",
    "\n",
    "# Plot the training and validation accuracies\n",
    "print(\"Plotting the training and validation accuracies...\")\n",
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e418c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using these hardcoded values as obtained from confusion matrix above inorder to make a plot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Confusion matrix data\n",
    "confusion_matrix = np.array([\n",
    "    [848, 6, 46, 12, 9, 3, 5, 12, 41, 18],\n",
    "    [18, 889, 3, 7, 2, 0, 3, 5, 17, 56],\n",
    "    [55, 0, 704, 36, 87, 30, 53, 28, 7, 0],\n",
    "    [19, 1, 64, 660, 51, 116, 40, 38, 7, 4],\n",
    "    [12, 1, 43, 44, 814, 16, 23, 41, 5, 1],\n",
    "    [9, 1, 53, 151, 39, 695, 6, 42, 2, 2],\n",
    "    [5, 1, 48, 52, 27, 13, 842, 6, 4, 2],\n",
    "    [10, 1, 28, 24, 30, 18, 0, 886, 1, 2],\n",
    "    [51, 11, 9, 7, 3, 4, 3, 2, 903, 7],\n",
    "    [25, 45, 5, 6, 4, 4, 2, 8, 20, 881]\n",
    "])\n",
    "\n",
    "# Class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
